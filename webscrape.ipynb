{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tweepy geopandas shapely pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for searching all around the world (without geolocation limitations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# === Configuration ===\n",
    "# Replace with your Twitter API Bearer Token\n",
    "bearer_token = \"your_bearer_token_here\"\n",
    "\n",
    "# Initialize the client\n",
    "client = tweepy.Client(bearer_token=bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# Define your query: tweets containing \"flood\" OR \"banjir\" and \"Indonesia\" (excluding retweets)\n",
    "query = '(flood OR banjir) -is:retweet'\n",
    "\n",
    "# Define your time range in ISO 8601 format (UTC); note that recent search only supports past 7 days\n",
    "# Adjust these dates as needed (e.g., for this month, if within the last 7 days)\n",
    "start_time = \"2025-03-01T00:00:00Z\"\n",
    "end_time   = \"2025-03-04T00:00:00Z\"\n",
    "\n",
    "# === Searching Tweets with Geo Information ===\n",
    "# Request tweet fields (created_at and geo), expansions for geo.place_id, and place fields (including bounding box)\n",
    "tweets = client.search_recent_tweets(\n",
    "    query=query,\n",
    "    tweet_fields=['created_at', 'geo'],\n",
    "    expansions=['geo.place_id'],\n",
    "    place_fields=['full_name', 'geo'],\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    max_results=100  # Adjust as needed (max allowed per request is 100)\n",
    ")\n",
    "\n",
    "# Check if any tweets were returned\n",
    "if tweets.data is None:\n",
    "    print(\"No tweets found with the given query and time range.\")\n",
    "    exit()\n",
    "\n",
    "# Build a mapping from place_id to place info\n",
    "places = {}\n",
    "if tweets.includes and \"places\" in tweets.includes:\n",
    "    for place in tweets.includes[\"places\"]:\n",
    "        places[place.id] = place\n",
    "\n",
    "data = []\n",
    "# Process each tweet to extract location info\n",
    "for tweet in tweets.data:\n",
    "    if tweet.geo and \"place_id\" in tweet.geo:\n",
    "        place_id = tweet.geo[\"place_id\"]\n",
    "        # Check if the place info exists and has bounding box data\n",
    "        if place_id in places and places[place_id].geo and \"bbox\" in places[place_id].geo:\n",
    "            bbox = places[place_id].geo[\"bbox\"]  # Format: [west_long, south_lat, east_long, north_lat]\n",
    "            # Calculate the centroid of the bounding box\n",
    "            lon = (bbox[0] + bbox[2]) / 2\n",
    "            lat = (bbox[1] + bbox[3]) / 2\n",
    "            data.append({\n",
    "                \"id\": tweet.id,\n",
    "                \"date\": tweet.created_at,\n",
    "                \"content\": tweet.text,\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"place\": places[place_id].full_name\n",
    "            })\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Found {len(df)} tweets with location data.\")\n",
    "\n",
    "# === Creating a GeoDataFrame and Exporting ===\n",
    "if not df.empty:\n",
    "    # Create a geometry column from longitude and latitude\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")  # WGS84\n",
    "\n",
    "    # Export to GeoJSON for QGIS\n",
    "    geojson_path = \"tweets_flood_indonesia.geojson\"\n",
    "    gdf.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "    print(f\"GeoJSON saved to {geojson_path}\")\n",
    "\n",
    "    # Export to Shapefile for QGIS\n",
    "    shapefile_path = \"tweets_flood_indonesia.shp\"\n",
    "    gdf.to_file(shapefile_path)\n",
    "    print(f\"Shapefile saved to {shapefile_path}\")\n",
    "else:\n",
    "    print(\"No tweets with geo information were found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this to search the tweet inside certain coordinates (in the example is the extent for Indonesia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 724 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1896712184765223096 does not include geo information.\n",
      "Tweet 1896712171759022586 does not include geo information.\n",
      "Tweet 1896712167790948626 does not include geo information.\n",
      "Tweet 1896712158907650522 does not include geo information.\n",
      "Tweet 1896712156265292115 does not include geo information.\n",
      "Tweet 1896712149080420607 does not include geo information.\n",
      "Tweet 1896712145854996875 does not include geo information.\n",
      "Tweet 1896712136132612335 does not include geo information.\n",
      "Tweet 1896712135612530907 does not include geo information.\n",
      "Tweet 1896712121695739996 does not include geo information.\n",
      "Tweet 1896712114167030107 does not include geo information.\n",
      "Tweet 1896712072609890353 does not include geo information.\n",
      "Tweet 1896712066754621620 does not include geo information.\n",
      "Tweet 1896712060647735452 does not include geo information.\n",
      "Tweet 1896711999616385190 does not include geo information.\n",
      "Tweet 1896711994184700013 does not include geo information.\n",
      "Tweet 1896711985145995330 does not include geo information.\n",
      "Tweet 1896711954355347703 does not include geo information.\n",
      "Tweet 1896711948471005186 does not include geo information.\n",
      "Tweet 1896711901465419908 does not include geo information.\n",
      "Tweet 1896711899938713679 does not include geo information.\n",
      "Tweet 1896711892720341183 does not include geo information.\n",
      "Filtered out tweet 1896711888840655133 - computed coordinates (37.0855815, -113.57776575) not in Indonesia.\n",
      "Tweet 1896711883333456321 does not include geo information.\n",
      "Tweet 1896711874370326934 does not include geo information.\n",
      "Tweet 1896711870817644849 does not include geo information.\n",
      "Tweet 1896711851452547151 does not include geo information.\n",
      "Tweet 1896711816019148974 does not include geo information.\n",
      "Tweet 1896711813754126674 does not include geo information.\n",
      "Tweet 1896711788991005005 does not include geo information.\n",
      "Tweet 1896711784616296959 does not include geo information.\n",
      "Tweet 1896711783777464328 does not include geo information.\n",
      "Tweet 1896711782393319583 does not include geo information.\n",
      "Tweet 1896711776118747553 does not include geo information.\n",
      "Tweet 1896711717989822817 does not include geo information.\n",
      "Tweet 1896711717935263816 does not include geo information.\n",
      "Tweet 1896711710729539743 does not include geo information.\n",
      "Tweet 1896711698482139168 does not include geo information.\n",
      "Tweet 1896711689896436060 does not include geo information.\n",
      "Tweet 1896711688147406977 does not include geo information.\n",
      "Tweet 1896711686796816565 does not include geo information.\n",
      "Tweet 1896711684531884266 does not include geo information.\n",
      "Tweet 1896711675006587068 does not include geo information.\n",
      "Tweet 1896711662222327944 does not include geo information.\n",
      "Tweet 1896711639145332926 does not include geo information.\n",
      "Tweet 1896711614856048934 does not include geo information.\n",
      "Tweet 1896711612419154345 does not include geo information.\n",
      "Tweet 1896711610938589442 does not include geo information.\n",
      "Tweet 1896711606777851911 does not include geo information.\n",
      "Tweet 1896711605435678849 does not include geo information.\n",
      "Tweet 1896711605045604418 does not include geo information.\n",
      "Tweet 1896711595205734638 does not include geo information.\n",
      "Tweet 1896711581968547968 does not include geo information.\n",
      "Tweet 1896711568890679670 does not include geo information.\n",
      "Tweet 1896711568605544859 does not include geo information.\n",
      "Tweet 1896711562800549890 does not include geo information.\n",
      "Tweet 1896711544312041568 does not include geo information.\n",
      "Tweet 1896711527522300036 does not include geo information.\n",
      "Tweet 1896711524099784735 does not include geo information.\n",
      "Tweet 1896711514893271266 does not include geo information.\n",
      "Tweet 1896711505330237638 does not include geo information.\n",
      "Tweet 1896711469456339451 does not include geo information.\n",
      "Tweet 1896711456105836929 does not include geo information.\n",
      "Tweet 1896711438074564872 does not include geo information.\n",
      "Tweet 1896711436572991707 does not include geo information.\n",
      "Tweet 1896711435885117678 does not include geo information.\n",
      "Tweet 1896711433863516628 does not include geo information.\n",
      "Tweet 1896711414250688966 does not include geo information.\n",
      "Tweet 1896711412925559128 does not include geo information.\n",
      "Tweet 1896711406499852419 does not include geo information.\n",
      "Tweet 1896711404310372530 does not include geo information.\n",
      "Tweet 1896711399403053200 does not include geo information.\n",
      "Tweet 1896711386732052803 does not include geo information.\n",
      "Tweet 1896711384831807584 does not include geo information.\n",
      "Tweet 1896711375201939572 does not include geo information.\n",
      "Tweet 1896711367736090933 does not include geo information.\n",
      "Tweet 1896711362006683877 does not include geo information.\n",
      "Tweet 1896711337348387319 does not include geo information.\n",
      "Tweet 1896711334601126383 does not include geo information.\n",
      "Tweet 1896711327240126771 does not include geo information.\n",
      "Tweet 1896711323406434427 does not include geo information.\n",
      "Tweet 1896711312404824512 does not include geo information.\n",
      "Tweet 1896711307874980086 does not include geo information.\n",
      "Tweet 1896711303647117317 does not include geo information.\n",
      "Tweet 1896711302695030961 does not include geo information.\n",
      "Tweet 1896711259481051581 does not include geo information.\n",
      "Tweet 1896711259334361142 does not include geo information.\n",
      "Tweet 1896711254372393415 does not include geo information.\n",
      "Tweet 1896711217689112966 does not include geo information.\n",
      "Tweet 1896711199846433156 does not include geo information.\n",
      "Tweet 1896711190925242826 does not include geo information.\n",
      "Tweet 1896711182620475625 does not include geo information.\n",
      "Tweet 1896711166958948391 does not include geo information.\n",
      "Tweet 1896711155948867851 does not include geo information.\n",
      "Tweet 1896711152387924235 does not include geo information.\n",
      "Tweet 1896711149913288746 does not include geo information.\n",
      "Tweet 1896711132930625731 does not include geo information.\n",
      "Tweet 1896711127595426116 does not include geo information.\n",
      "Tweet 1896711123648540701 does not include geo information.\n",
      "Found 1 tweets with location data in Indonesia.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'tweets_flood_indonesia.geojson'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Export to GeoJSON for QGIS\u001b[39;00m\n\u001b[0;32m     86\u001b[0m geojson_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweets_flood_indonesia.geojson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 87\u001b[0m \u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeojson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGeoJSON\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoJSON saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeojson_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Export to Shapefile for QGIS\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\geopandas\\geodataframe.py:1536\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[1;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m \n\u001b[0;32m   1443\u001b[0m \u001b[38;5;124;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1532\u001b[0m \n\u001b[0;32m   1533\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[1;32m-> 1536\u001b[0m _to_file(\u001b[38;5;28mself\u001b[39m, filename, driver, schema, index, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\geopandas\\io\\file.py:686\u001b[0m, in \u001b[0;36m_to_file\u001b[1;34m(df, filename, driver, schema, index, mode, crs, engine, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 686\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, metadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    688\u001b[0m     _to_file_fiona(df, filename, driver, schema, crs, mode, metadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\geopandas\\io\\file.py:748\u001b[0m, in \u001b[0;36m_to_file_pyogrio\u001b[1;34m(df, filename, driver, schema, crs, mode, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoDataFrame cannot contain duplicated column names.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 748\u001b[0m pyogrio\u001b[38;5;241m.\u001b[39mwrite_dataframe(df, filename, driver\u001b[38;5;241m=\u001b[39mdriver, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyogrio\\geopandas.py:662\u001b[0m, in \u001b[0;36mwrite_dataframe\u001b[1;34m(df, path, layer, driver, encoding, geometry_type, promote_to_multi, nan_as_null, append, use_arrow, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geometry_column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    660\u001b[0m     geometry \u001b[38;5;241m=\u001b[39m to_wkb(geometry\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m--> 662\u001b[0m write(\n\u001b[0;32m    663\u001b[0m     path,\n\u001b[0;32m    664\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    665\u001b[0m     driver\u001b[38;5;241m=\u001b[39mdriver,\n\u001b[0;32m    666\u001b[0m     geometry\u001b[38;5;241m=\u001b[39mgeometry,\n\u001b[0;32m    667\u001b[0m     field_data\u001b[38;5;241m=\u001b[39mfield_data,\n\u001b[0;32m    668\u001b[0m     field_mask\u001b[38;5;241m=\u001b[39mfield_mask,\n\u001b[0;32m    669\u001b[0m     fields\u001b[38;5;241m=\u001b[39mfields,\n\u001b[0;32m    670\u001b[0m     crs\u001b[38;5;241m=\u001b[39mcrs,\n\u001b[0;32m    671\u001b[0m     geometry_type\u001b[38;5;241m=\u001b[39mgeometry_type,\n\u001b[0;32m    672\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    673\u001b[0m     promote_to_multi\u001b[38;5;241m=\u001b[39mpromote_to_multi,\n\u001b[0;32m    674\u001b[0m     nan_as_null\u001b[38;5;241m=\u001b[39mnan_as_null,\n\u001b[0;32m    675\u001b[0m     append\u001b[38;5;241m=\u001b[39mappend,\n\u001b[0;32m    676\u001b[0m     dataset_metadata\u001b[38;5;241m=\u001b[39mdataset_metadata,\n\u001b[0;32m    677\u001b[0m     layer_metadata\u001b[38;5;241m=\u001b[39mlayer_metadata,\n\u001b[0;32m    678\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    679\u001b[0m     dataset_options\u001b[38;5;241m=\u001b[39mdataset_options,\n\u001b[0;32m    680\u001b[0m     layer_options\u001b[38;5;241m=\u001b[39mlayer_options,\n\u001b[0;32m    681\u001b[0m     gdal_tz_offsets\u001b[38;5;241m=\u001b[39mgdal_tz_offsets,\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    683\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyogrio\\raw.py:723\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(path, geometry, field_data, fields, field_mask, layer, driver, geometry_type, crs, encoding, promote_to_multi, nan_as_null, append, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, gdal_tz_offsets, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;66;03m# preprocess kwargs and split in dataset and layer creation options\u001b[39;00m\n\u001b[0;32m    719\u001b[0m dataset_kwargs, layer_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_kwargs(\n\u001b[0;32m    720\u001b[0m     driver, dataset_options, layer_options, kwargs\n\u001b[0;32m    721\u001b[0m )\n\u001b[1;32m--> 723\u001b[0m \u001b[43mogr_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:2307\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_write\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:2102\u001b[0m, in \u001b[0;36mpyogrio._io.create_ogr_dataset_layer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'tweets_flood_indonesia.geojson'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# === Configuration ===\n",
    "# Replace with your Twitter API Bearer Token\n",
    "bearer_token = \"insert_your_bearer_token_here\"\n",
    "\n",
    "# Initialize the client\n",
    "client = tweepy.Client(bearer_token=bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# Define your query: tweets containing \"flood\" OR \"banjir\" and \"Indonesia\" (excluding retweets)\n",
    "query = '(flood OR banjir) -is:retweet'\n",
    "\n",
    "# Define your time range in ISO 8601 format (UTC)\n",
    "start_time = \"2025-03-01T00:00:00Z\"\n",
    "end_time   = \"2025-03-04T00:00:00Z\"\n",
    "\n",
    "# === Helper: Check if coordinates are in Indonesia ===\n",
    "def in_indonesia(lat, lon):\n",
    "    # Approximate bounding box for Indonesia:\n",
    "    # Latitude roughly between -11 and 6, longitude between 95 and 141.\n",
    "    return (-11 <= lat <= 6) and (95 <= lon <= 141)\n",
    "\n",
    "# === Searching Tweets with Geo Information ===\n",
    "tweets = client.search_recent_tweets(\n",
    "    query=query,\n",
    "    tweet_fields=['created_at', 'geo'],\n",
    "    expansions=['geo.place_id'],\n",
    "    place_fields=['full_name', 'geo'],\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    max_results=100  # Maximum allowed per request; adjust as needed\n",
    ")\n",
    "\n",
    "if tweets.data is None:\n",
    "    print(\"No tweets found with the given query and time range.\")\n",
    "    exit()\n",
    "\n",
    "# Build a mapping from place_id to place info\n",
    "places = {}\n",
    "if tweets.includes and \"places\" in tweets.includes:\n",
    "    for place in tweets.includes[\"places\"]:\n",
    "        places[place.id] = place\n",
    "\n",
    "data = []\n",
    "for tweet in tweets.data:\n",
    "    if tweet.geo and \"place_id\" in tweet.geo:\n",
    "        place_id = tweet.geo[\"place_id\"]\n",
    "        # Check if the place info exists and has bounding box data\n",
    "        if place_id in places and places[place_id].geo and \"bbox\" in places[place_id].geo:\n",
    "            bbox = places[place_id].geo[\"bbox\"]  # Format: [west_long, south_lat, east_long, north_lat]\n",
    "            # Calculate the centroid of the bounding box\n",
    "            lon = (bbox[0] + bbox[2]) / 2\n",
    "            lat = (bbox[1] + bbox[3]) / 2\n",
    "\n",
    "            # Filter out points that are not in Indonesia\n",
    "            if in_indonesia(lat, lon):\n",
    "                data.append({\n",
    "                    \"id\": tweet.id,\n",
    "                    \"date\": tweet.created_at,\n",
    "                    \"content\": tweet.text,\n",
    "                    \"latitude\": lat,\n",
    "                    \"longitude\": lon,\n",
    "                    \"place\": places[place_id].full_name\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Filtered out tweet {tweet.id} - computed coordinates ({lat}, {lon}) not in Indonesia.\")\n",
    "        else:\n",
    "            print(f\"Tweet {tweet.id} has no valid bounding box info.\")\n",
    "    else:\n",
    "        print(f\"Tweet {tweet.id} does not include geo information.\")\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Found {len(df)} tweets with location data in Indonesia.\")\n",
    "\n",
    "# === Creating a GeoDataFrame and Exporting ===\n",
    "if not df.empty:\n",
    "    # Create geometry column from longitude and latitude\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")  # WGS84\n",
    "\n",
    "    # Export to GeoJSON for QGIS\n",
    "    geojson_path = \"tweets_flood_indonesia.geojson\"\n",
    "    gdf.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "    print(f\"GeoJSON saved to {geojson_path}\")\n",
    "\n",
    "    # Export to Shapefile for QGIS\n",
    "    shapefile_path = \"tweets_flood_indonesia.shp\"\n",
    "    gdf.to_file(shapefile_path)\n",
    "    print(f\"Shapefile saved to {shapefile_path}\")\n",
    "else:\n",
    "    print(\"No tweets with geo information in Indonesia were found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
