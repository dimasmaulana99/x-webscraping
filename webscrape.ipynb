{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tweepy geopandas shapely pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for searching all around the world (without geolocation limitations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# === Configuration ===\n",
    "# Replace with your Twitter API Bearer Token\n",
    "bearer_token = \"your_bearer_token_here\"\n",
    "\n",
    "# Initialize the client\n",
    "client = tweepy.Client(bearer_token=bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# Define your query: tweets containing \"flood\" OR \"banjir\" and \"Indonesia\" (excluding retweets)\n",
    "query = '(flood OR banjir) -is:retweet'\n",
    "\n",
    "# Define your time range in ISO 8601 format (UTC); note that recent search only supports past 7 days\n",
    "# Adjust these dates as needed (e.g., for this month, if within the last 7 days)\n",
    "start_time = \"2025-03-01T00:00:00Z\"\n",
    "end_time   = \"2025-03-04T00:00:00Z\"\n",
    "\n",
    "# === Searching Tweets with Geo Information ===\n",
    "# Request tweet fields (created_at and geo), expansions for geo.place_id, and place fields (including bounding box)\n",
    "tweets = client.search_recent_tweets(\n",
    "    query=query,\n",
    "    tweet_fields=['created_at', 'geo'],\n",
    "    expansions=['geo.place_id'],\n",
    "    place_fields=['full_name', 'geo'],\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    max_results=100  # Adjust as needed (max allowed per request is 100)\n",
    ")\n",
    "\n",
    "# Check if any tweets were returned\n",
    "if tweets.data is None:\n",
    "    print(\"No tweets found with the given query and time range.\")\n",
    "    exit()\n",
    "\n",
    "# Build a mapping from place_id to place info\n",
    "places = {}\n",
    "if tweets.includes and \"places\" in tweets.includes:\n",
    "    for place in tweets.includes[\"places\"]:\n",
    "        places[place.id] = place\n",
    "\n",
    "data = []\n",
    "# Process each tweet to extract location info\n",
    "for tweet in tweets.data:\n",
    "    if tweet.geo and \"place_id\" in tweet.geo:\n",
    "        place_id = tweet.geo[\"place_id\"]\n",
    "        # Check if the place info exists and has bounding box data\n",
    "        if place_id in places and places[place_id].geo and \"bbox\" in places[place_id].geo:\n",
    "            bbox = places[place_id].geo[\"bbox\"]  # Format: [west_long, south_lat, east_long, north_lat]\n",
    "            # Calculate the centroid of the bounding box\n",
    "            lon = (bbox[0] + bbox[2]) / 2\n",
    "            lat = (bbox[1] + bbox[3]) / 2\n",
    "            data.append({\n",
    "                \"id\": tweet.id,\n",
    "                \"date\": tweet.created_at,\n",
    "                \"content\": tweet.text,\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"place\": places[place_id].full_name\n",
    "            })\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Found {len(df)} tweets with location data.\")\n",
    "\n",
    "# === Creating a GeoDataFrame and Exporting ===\n",
    "if not df.empty:\n",
    "    # Create a geometry column from longitude and latitude\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")  # WGS84\n",
    "\n",
    "    # Export to GeoJSON for QGIS\n",
    "    geojson_path = \"tweets_flood_indonesia.geojson\"\n",
    "    gdf.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "    print(f\"GeoJSON saved to {geojson_path}\")\n",
    "\n",
    "    # Export to Shapefile for QGIS\n",
    "    shapefile_path = \"tweets_flood_indonesia.shp\"\n",
    "    gdf.to_file(shapefile_path)\n",
    "    print(f\"Shapefile saved to {shapefile_path}\")\n",
    "else:\n",
    "    print(\"No tweets with geo information were found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this to search the tweet inside certain coordinates (in the example is the extent for Indonesia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# === Configuration ===\n",
    "# Replace with your Twitter API Bearer Token\n",
    "bearer_token = \"insert_your_bearer_token_here\"\n",
    "\n",
    "# Initialize the client\n",
    "client = tweepy.Client(bearer_token=bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# Define your query: tweets containing \"flood\" OR \"banjir\" and \"Indonesia\" (excluding retweets)\n",
    "query = '(flood OR banjir) -is:retweet'\n",
    "\n",
    "# Define your time range in ISO 8601 format (UTC)\n",
    "start_time = \"2025-03-01T00:00:00Z\"\n",
    "end_time   = \"2025-03-04T00:00:00Z\"\n",
    "\n",
    "# === Helper: Check if coordinates are in Indonesia ===\n",
    "def in_indonesia(lat, lon):\n",
    "    # Approximate bounding box for Indonesia:\n",
    "    # Latitude roughly between -11 and 6, longitude between 95 and 141.\n",
    "    return (-11 <= lat <= 6) and (95 <= lon <= 141)\n",
    "\n",
    "# === Searching Tweets with Geo Information ===\n",
    "tweets = client.search_recent_tweets(\n",
    "    query=query,\n",
    "    tweet_fields=['created_at', 'geo'],\n",
    "    expansions=['geo.place_id'],\n",
    "    place_fields=['full_name', 'geo'],\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    max_results=100  # Maximum allowed per request; adjust as needed\n",
    ")\n",
    "\n",
    "if tweets.data is None:\n",
    "    print(\"No tweets found with the given query and time range.\")\n",
    "    exit()\n",
    "\n",
    "# Build a mapping from place_id to place info\n",
    "places = {}\n",
    "if tweets.includes and \"places\" in tweets.includes:\n",
    "    for place in tweets.includes[\"places\"]:\n",
    "        places[place.id] = place\n",
    "\n",
    "data = []\n",
    "for tweet in tweets.data:\n",
    "    if tweet.geo and \"place_id\" in tweet.geo:\n",
    "        place_id = tweet.geo[\"place_id\"]\n",
    "        # Check if the place info exists and has bounding box data\n",
    "        if place_id in places and places[place_id].geo and \"bbox\" in places[place_id].geo:\n",
    "            bbox = places[place_id].geo[\"bbox\"]  # Format: [west_long, south_lat, east_long, north_lat]\n",
    "            # Calculate the centroid of the bounding box\n",
    "            lon = (bbox[0] + bbox[2]) / 2\n",
    "            lat = (bbox[1] + bbox[3]) / 2\n",
    "\n",
    "            # Filter out points that are not in Indonesia\n",
    "            if in_indonesia(lat, lon):\n",
    "                data.append({\n",
    "                    \"id\": tweet.id,\n",
    "                    \"date\": tweet.created_at,\n",
    "                    \"content\": tweet.text,\n",
    "                    \"latitude\": lat,\n",
    "                    \"longitude\": lon,\n",
    "                    \"place\": places[place_id].full_name\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Filtered out tweet {tweet.id} - computed coordinates ({lat}, {lon}) not in Indonesia.\")\n",
    "        else:\n",
    "            print(f\"Tweet {tweet.id} has no valid bounding box info.\")\n",
    "    else:\n",
    "        print(f\"Tweet {tweet.id} does not include geo information.\")\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Found {len(df)} tweets with location data in Indonesia.\")\n",
    "\n",
    "# === Creating a GeoDataFrame and Exporting ===\n",
    "if not df.empty:\n",
    "    # Create geometry column from longitude and latitude\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")  # WGS84\n",
    "\n",
    "    # Export to GeoJSON for QGIS\n",
    "    geojson_path = \"tweets_flood_indonesia.geojson\"\n",
    "    gdf.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "    print(f\"GeoJSON saved to {geojson_path}\")\n",
    "\n",
    "    # Export to Shapefile for QGIS\n",
    "    shapefile_path = \"tweets_flood_indonesia.shp\"\n",
    "    gdf.to_file(shapefile_path)\n",
    "    print(f\"Shapefile saved to {shapefile_path}\")\n",
    "else:\n",
    "    print(\"No tweets with geo information in Indonesia were found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
